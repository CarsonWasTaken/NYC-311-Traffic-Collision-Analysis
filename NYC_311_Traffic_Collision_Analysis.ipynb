{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install sodapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DxD1QbfuYw0",
        "outputId": "3517ae0b-b59c-4614-9c5e-e76a866c72dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sodapy\n",
            "  Downloading sodapy-2.2.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from sodapy) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (2025.4.26)\n",
            "Downloading sodapy-2.2.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: sodapy\n",
            "Successfully installed sodapy-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLwFootxtTsV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sodapy import Socrata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract 311 dataset\n",
        "\n",
        "data_url='data.cityofnewyork.us'\n",
        "data_set='erm2-nwe9'\n",
        "app_token='FcPWK08jZ0p37WqjzGoBF2dNV'\n",
        "client = Socrata(data_url,app_token)\n",
        "client.timeout = 300\n",
        "results = client.get(data_set, limit = 2000000)\n",
        "df = pd.DataFrame.from_records(results)\n",
        "df.to_csv(\"311_requests.csv\")"
      ],
      "metadata": {
        "id": "SXWilbphuRSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('311_requests.csv')\n",
        "\n",
        "# Examine the dataset\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "missing_info = pd.DataFrame({\n",
        "    'Missing Values': missing_values,\n",
        "    'Percentage': missing_percentage\n",
        "})\n",
        "print(missing_info[missing_info['Missing Values'] > 0].sort_values('Missing Values', ascending=False))\n",
        "# Transform: Remove unnecessary columns and handle missing values\n",
        "\n",
        "# Define which columns to keep\n",
        "# Keep essential columns like date, complaint type, borough, etc.\n",
        "columns_to_keep = [\n",
        "    'unique_key',           # Identifier for each complaint\n",
        "    'created_date',         # When the complaint was filed\n",
        "    'closed_date',          # When the complaint was resolved\n",
        "    'agency',               # Responding agency code\n",
        "    'complaint_type',       # Type of complaint (crucial for multiple KPIs)\n",
        "    'descriptor',           # Additional details about the complaint\n",
        "    'incident_zip',         # Zip code for location analysis\n",
        "    'borough',              # Borough information for location analysis\n",
        "    'status',               # Current status (Open/Closed)\n",
        "    'location_type',        # To identify street-related complaints\n",
        "    'incident_address',     # For precise location matching with collision data\n",
        "    'street_name',          # For street-level analysis\n",
        "]\n",
        "\n",
        "# Keep only the columns needed\n",
        "df_cleaned = df[columns_to_keep]\n",
        "print(f\"\\nDataset shape after removing unnecessary columns: {df_cleaned.shape}\")\n",
        "\n",
        "df_no_blanks = df_cleaned.dropna(subset=['incident_zip'])\n",
        "print(f\"\\nDataset shape after removing blank zip codes: {df_no_blanks.shape}\")\n",
        "\n",
        "df_no_blanks = df_cleaned.dropna(subset=['location_type'])\n",
        "print(f\"\\nDataset shape after removing blank location types: {df_no_blanks.shape}\")\n",
        "\n",
        "# Handle missing values\n",
        "df_smart_clean = df_cleaned.copy()\n",
        "\n",
        "# Load: Save the processed data\n",
        "df_smart_clean.to_csv('cleaned_311_requests.csv', index=False)\n",
        "print(\"\\nETL process completed. Data saved to 'cleaned_311_requests.csv'\")\n",
        "\n",
        "# Data summary after cleaning\n",
        "print(\"\\nSample of cleaned data:\")\n",
        "print(df_smart_clean.head())\n",
        "\n",
        "print(\"\\nSummary statistics for numeric columns:\")\n",
        "print(df_smart_clean.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu37iIk6DjJo",
        "outputId": "06b08679-ecc8-4843-ccaf-630183afbea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (10000, 48)\n",
            "\n",
            "Column names:\n",
            "['Unnamed: 0', 'unique_key', 'created_date', 'closed_date', 'agency', 'agency_name', 'complaint_type', 'descriptor', 'incident_zip', 'incident_address', 'street_name', 'address_type', 'city', 'facility_type', 'status', 'resolution_action_updated_date', 'community_board', 'bbl', 'borough', 'x_coordinate_state_plane', 'y_coordinate_state_plane', 'open_data_channel_type', 'park_facility_name', 'park_borough', 'latitude', 'longitude', 'location', ':@computed_region_efsh_h5xi', ':@computed_region_f5dn_yrer', ':@computed_region_yeji_bk3q', ':@computed_region_92fq_4b7q', ':@computed_region_sbqj_enih', ':@computed_region_7mpf_4k6g', 'resolution_description', 'location_type', 'cross_street_1', 'cross_street_2', 'intersection_street_1', 'intersection_street_2', 'landmark', 'vehicle_type', 'taxi_pick_up_location', 'bridge_highway_name', 'bridge_highway_segment', 'due_date', 'bridge_highway_direction', 'road_ramp', 'taxi_company_borough']\n",
            "\n",
            "Missing values per column:\n",
            "                                Missing Values  Percentage\n",
            "taxi_company_borough                      9992       99.92\n",
            "facility_type                             9986       99.86\n",
            "road_ramp                                 9977       99.77\n",
            "bridge_highway_direction                  9976       99.76\n",
            "bridge_highway_segment                    9952       99.52\n",
            "bridge_highway_name                       9952       99.52\n",
            "due_date                                  9946       99.46\n",
            "taxi_pick_up_location                     9891       98.91\n",
            "vehicle_type                              9465       94.65\n",
            "closed_date                               4954       49.54\n",
            "landmark                                  3278       32.78\n",
            "resolution_description                    3059       30.59\n",
            "resolution_action_updated_date            2675       26.75\n",
            "intersection_street_1                     2560       25.60\n",
            "intersection_street_2                     2547       25.47\n",
            "cross_street_1                            2232       22.32\n",
            "cross_street_2                            2219       22.19\n",
            "bbl                                       1197       11.97\n",
            "location_type                             1142       11.42\n",
            "city                                       532        5.32\n",
            "street_name                                330        3.30\n",
            "incident_address                           330        3.30\n",
            ":@computed_region_efsh_h5xi                223        2.23\n",
            "descriptor                                 201        2.01\n",
            ":@computed_region_7mpf_4k6g                194        1.94\n",
            ":@computed_region_yeji_bk3q                194        1.94\n",
            ":@computed_region_92fq_4b7q                194        1.94\n",
            ":@computed_region_f5dn_yrer                194        1.94\n",
            ":@computed_region_sbqj_enih                194        1.94\n",
            "location                                   192        1.92\n",
            "y_coordinate_state_plane                   192        1.92\n",
            "longitude                                  192        1.92\n",
            "x_coordinate_state_plane                   192        1.92\n",
            "latitude                                   192        1.92\n",
            "incident_zip                                77        0.77\n",
            "address_type                                35        0.35\n",
            "park_facility_name                          19        0.19\n",
            "\n",
            "Dataset shape after removing unnecessary columns: (10000, 12)\n",
            "\n",
            "Dataset shape after removing blank zip codes: (9923, 12)\n",
            "\n",
            "Dataset shape after removing blank location types: (8858, 12)\n",
            "\n",
            "ETL process completed. Data saved to 'cleaned_311_requests.csv'\n",
            "\n",
            "Sample of cleaned data:\n",
            "   unique_key             created_date              closed_date agency  \\\n",
            "0    64882005  2025-05-09T02:09:33.000  2025-05-09T02:22:23.000   DSNY   \n",
            "1    64890474  2025-05-09T02:03:45.000                      NaN   DSNY   \n",
            "2    64888983  2025-05-09T01:59:50.000                      NaN   DSNY   \n",
            "3    64890807  2025-05-09T01:50:47.000                      NaN   NYPD   \n",
            "4    64889331  2025-05-09T01:50:31.000                      NaN   NYPD   \n",
            "\n",
            "            complaint_type       descriptor  incident_zip   borough  \\\n",
            "0                 Graffiti         Graffiti       11238.0  BROOKLYN   \n",
            "1                 Graffiti         Graffiti       11238.0  BROOKLYN   \n",
            "2                 Graffiti         Graffiti       11238.0  BROOKLYN   \n",
            "3  Noise - Street/Sidewalk     Loud Talking       10474.0     BRONX   \n",
            "4          Illegal Parking  Blocked Hydrant       11373.0    QUEENS   \n",
            "\n",
            "        status    location_type       incident_address      street_name  \n",
            "0       Closed              NaN      174 CLIFTON PLACE    CLIFTON PLACE  \n",
            "1         Open              NaN      119 CLIFTON PLACE    CLIFTON PLACE  \n",
            "2         Open              NaN      115 CLIFTON PLACE    CLIFTON PLACE  \n",
            "3  In Progress  Street/Sidewalk     1204 GILBERT PLACE    GILBERT PLACE  \n",
            "4  In Progress  Street/Sidewalk  78-12 KNEELAND AVENUE  KNEELAND AVENUE  \n",
            "\n",
            "Summary statistics for numeric columns:\n",
            "         unique_key  incident_zip\n",
            "count  1.000000e+04   9923.000000\n",
            "mean   6.488633e+07  10841.596997\n",
            "std    3.173902e+03    542.445620\n",
            "min    6.487104e+07  10000.000000\n",
            "25%    6.488362e+07  10451.000000\n",
            "50%    6.488632e+07  11207.000000\n",
            "75%    6.488903e+07  11236.000000\n",
            "max    6.489176e+07  11694.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract Motor Collisions dataset\n",
        "\n",
        "data_url='data.cityofnewyork.us'\n",
        "data_set='h9gi-nx95'\n",
        "app_token='FcPWK08jZ0p37WqjzGoBF2dNV'\n",
        "client = Socrata(data_url,app_token)\n",
        "client.timeout = 300\n",
        "results = client.get(data_set, limit = 10000)\n",
        "df = pd.DataFrame.from_records(results)\n",
        "df.to_csv(\"motor_collisions.csv\")"
      ],
      "metadata": {
        "id": "B-Ait5v7UK35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('motor_collisions.csv')\n",
        "\n",
        "# Examine the dataset\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "missing_info = pd.DataFrame({\n",
        "    'Missing Values': missing_values,\n",
        "    'Percentage': missing_percentage\n",
        "})\n",
        "print(missing_info[missing_info['Missing Values'] > 0].sort_values('Missing Values', ascending=False))\n",
        "# Transform: Remove unnecessary columns and handle missing values\n",
        "\n",
        "# Define which columns to keep\n",
        "# Keep essential columns like date, complaint type, borough, etc.\n",
        "columns_to_keep = [\n",
        "    'crash_date', 'crash_time', 'borough', 'zip_code', 'latitude',\n",
        "    'longitude', 'location', 'number_of_persons_injured',\n",
        "    'number_of_persons_killed', 'number_of_pedestrians_injured',\n",
        "    'number_of_pedestrians_killed', 'number_of_cyclist_injured',\n",
        "    'number_of_cyclist_killed', 'vehicle_type_code1',\n",
        "    'vehicle_type_code2',\n",
        "]\n",
        "\n",
        "# Keep only the columns needed\n",
        "df_cleaned = df[columns_to_keep]\n",
        "print(f\"\\nDataset shape after removing unnecessary columns: {df_cleaned.shape}\")\n",
        "\n",
        "df_no_blanks = df_cleaned.dropna()\n",
        "print(f\"\\nDataset shape after removing blank rows: {df_no_blanks.shape}\")\n",
        "\n",
        "# Handle missing values\n",
        "df_smart_clean = df_cleaned.copy()\n",
        "\n",
        "# 5. Load: Save the processed data\n",
        "df_smart_clean.to_csv('cleaned_motor_collisions.csv', index=False)\n",
        "print(\"\\nETL process completed. Data saved to 'cleaned_motor_collisions.csv'\")\n",
        "\n",
        "# 6. Data summary after cleaning\n",
        "print(\"\\nSample of cleaned data:\")\n",
        "print(df_smart_clean.head())\n",
        "\n",
        "print(\"\\nSummary statistics for numeric columns:\")\n",
        "print(df_smart_clean.describe())"
      ],
      "metadata": {
        "id": "WLpNGMlrUPBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66c8ecb-f3af-415e-9b70-bf061950b87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (10000, 30)\n",
            "\n",
            "Column names:\n",
            "['Unnamed: 0', 'crash_date', 'crash_time', 'on_street_name', 'off_street_name', 'number_of_persons_injured', 'number_of_persons_killed', 'number_of_pedestrians_injured', 'number_of_pedestrians_killed', 'number_of_cyclist_injured', 'number_of_cyclist_killed', 'number_of_motorist_injured', 'number_of_motorist_killed', 'contributing_factor_vehicle_1', 'contributing_factor_vehicle_2', 'collision_id', 'vehicle_type_code1', 'vehicle_type_code2', 'borough', 'zip_code', 'latitude', 'longitude', 'location', 'contributing_factor_vehicle_3', 'vehicle_type_code_3', 'cross_street_name', 'contributing_factor_vehicle_4', 'vehicle_type_code_4', 'contributing_factor_vehicle_5', 'vehicle_type_code_5']\n",
            "\n",
            "Missing values per column:\n",
            "                               Missing Values  Percentage\n",
            "vehicle_type_code_5                      9921       99.21\n",
            "contributing_factor_vehicle_5            9918       99.18\n",
            "vehicle_type_code_4                      9734       97.34\n",
            "contributing_factor_vehicle_4            9720       97.20\n",
            "vehicle_type_code_3                      9018       90.18\n",
            "contributing_factor_vehicle_3            8940       89.40\n",
            "cross_street_name                        7313       73.13\n",
            "off_street_name                          5357       53.57\n",
            "zip_code                                 3443       34.43\n",
            "borough                                  3440       34.40\n",
            "vehicle_type_code2                       3277       32.77\n",
            "on_street_name                           2687       26.87\n",
            "contributing_factor_vehicle_2            2190       21.90\n",
            "latitude                                  843        8.43\n",
            "longitude                                 843        8.43\n",
            "location                                  843        8.43\n",
            "vehicle_type_code1                        113        1.13\n",
            "contributing_factor_vehicle_1              47        0.47\n",
            "\n",
            "Dataset shape after removing unnecessary columns: (10000, 15)\n",
            "\n",
            "Dataset shape after removing blank rows: (4118, 15)\n",
            "\n",
            "ETL process completed. Data saved to 'cleaned_motor_collisions.csv'\n",
            "\n",
            "Sample of cleaned data:\n",
            "                crash_date crash_time   borough  zip_code  latitude  \\\n",
            "0  2021-09-11T00:00:00.000       2:39       NaN       NaN       NaN   \n",
            "1  2022-03-26T00:00:00.000      11:45       NaN       NaN       NaN   \n",
            "2  2023-11-01T00:00:00.000       1:29  BROOKLYN   11230.0  40.62179   \n",
            "3  2022-06-29T00:00:00.000       6:55       NaN       NaN       NaN   \n",
            "4  2022-09-21T00:00:00.000      13:21       NaN       NaN       NaN   \n",
            "\n",
            "   longitude                                           location  \\\n",
            "0        NaN                                                NaN   \n",
            "1        NaN                                                NaN   \n",
            "2 -73.970024  {'latitude': '40.62179', 'longitude': '-73.970...   \n",
            "3        NaN                                                NaN   \n",
            "4        NaN                                                NaN   \n",
            "\n",
            "   number_of_persons_injured  number_of_persons_killed  \\\n",
            "0                          2                         0   \n",
            "1                          1                         0   \n",
            "2                          1                         0   \n",
            "3                          0                         0   \n",
            "4                          0                         0   \n",
            "\n",
            "   number_of_pedestrians_injured  number_of_pedestrians_killed  \\\n",
            "0                              0                             0   \n",
            "1                              0                             0   \n",
            "2                              0                             0   \n",
            "3                              0                             0   \n",
            "4                              0                             0   \n",
            "\n",
            "   number_of_cyclist_injured  number_of_cyclist_killed  \\\n",
            "0                          0                         0   \n",
            "1                          0                         0   \n",
            "2                          0                         0   \n",
            "3                          0                         0   \n",
            "4                          0                         0   \n",
            "\n",
            "                    vehicle_type_code1 vehicle_type_code2  \n",
            "0                                Sedan              Sedan  \n",
            "1                                Sedan                NaN  \n",
            "2                                Moped              Sedan  \n",
            "3                                Sedan      Pick-up Truck  \n",
            "4  Station Wagon/Sport Utility Vehicle                NaN  \n",
            "\n",
            "Summary statistics for numeric columns:\n",
            "           zip_code     latitude    longitude  number_of_persons_injured  \\\n",
            "count   6557.000000  9157.000000  9157.000000               10000.000000   \n",
            "mean   10881.810737    40.524717   -73.553443                   0.467700   \n",
            "std      526.819738     2.849204     5.169897                   0.799263   \n",
            "min    10000.000000     0.000000   -74.244840                   0.000000   \n",
            "25%    10456.000000    40.665073   -73.962600                   0.000000   \n",
            "50%    11207.000000    40.713497   -73.920616                   0.000000   \n",
            "75%    11236.000000    40.786366   -73.870060                   1.000000   \n",
            "max    11694.000000    40.908310     0.000000                   9.000000   \n",
            "\n",
            "       number_of_persons_killed  number_of_pedestrians_injured  \\\n",
            "count              10000.000000                   10000.000000   \n",
            "mean                   0.003600                       0.067600   \n",
            "std                    0.061542                       0.260071   \n",
            "min                    0.000000                       0.000000   \n",
            "25%                    0.000000                       0.000000   \n",
            "50%                    0.000000                       0.000000   \n",
            "75%                    0.000000                       0.000000   \n",
            "max                    2.000000                       3.000000   \n",
            "\n",
            "       number_of_pedestrians_killed  number_of_cyclist_injured  \\\n",
            "count                  10000.000000               10000.000000   \n",
            "mean                       0.001500                   0.046800   \n",
            "std                        0.038703                   0.214975   \n",
            "min                        0.000000                   0.000000   \n",
            "25%                        0.000000                   0.000000   \n",
            "50%                        0.000000                   0.000000   \n",
            "75%                        0.000000                   0.000000   \n",
            "max                        1.000000                   2.000000   \n",
            "\n",
            "       number_of_cyclist_killed  \n",
            "count              10000.000000  \n",
            "mean                   0.000200  \n",
            "std                    0.014141  \n",
            "min                    0.000000  \n",
            "25%                    0.000000  \n",
            "50%                    0.000000  \n",
            "75%                    0.000000  \n",
            "max                    1.000000  \n"
          ]
        }
      ]
    }
  ]
}